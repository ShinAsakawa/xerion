{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xerion-demo001.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/xerion/blob/master/notebooks/xerion_demo001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "x1K11lyO9_iR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Disclaimer of Xerion, data management for simulating SM89 and PMSP96\n",
        "\n",
        "for [wbai handson](https://wba-initiative.org/3411/)\n",
        "\n",
        "<div>\n",
        "    <center><img src=\"https://wba-initiative.org/wp-content/uploads/2015/05/logo.png\" style=\"width:29%\"></center>\n",
        "</div>\n",
        "    \n",
        "\n",
        "<p style='text-align:center;'>\n",
        "    <font color='green' size='+1' style='font-weight:bold;'>Shin Asakawa &lt;asakawa@ieee.org&gt;</font>\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "AjELIKpl9_iS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 手順1. `Git clone` する"
      ]
    },
    {
      "metadata": {
        "id": "ricQMThk9_iT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8f0d63a-ef2f-40a5-f502-34567e201f35"
      },
      "cell_type": "code",
      "source": [
        "# GitHub から必要なパッケージを入手してください\n",
        "!git clone https://github.com/ShinAsakawa/xerion.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'xerion' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fobgjckeHMI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb37fb62-196c-430b-f922-57e45a25b4b2"
      },
      "cell_type": "code",
      "source": [
        "# numpy の不都合によりバージョンを変更します\n",
        "!pip install --user -U numpy==1.16.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: numpy==1.16.0 in /root/.local/lib/python3.6/site-packages (1.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z3bxw3on_Hpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "5aec361b-80f8-4053-9a22-366de0b207f1"
      },
      "cell_type": "code",
      "source": [
        "# 上で入手したパッケージをインストールします\n",
        "!pip install --user -U setuptools\n",
        "!pip install --user --upgrade ./xerion"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (40.8.0)\n",
            "Processing ./xerion\n",
            "Building wheels for collected packages: xerion\n",
            "  Building wheel for xerion (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-v979hs3n/wheels/4b/97/24/8adbd8d8f37b7470911c06e8466e900919e2e8f99a6c9e656a\n",
            "Successfully built xerion\n",
            "Installing collected packages: xerion\n",
            "  Found existing installation: xerion 0.3\n",
            "    Uninstalling xerion-0.3:\n",
            "      Successfully uninstalled xerion-0.3\n",
            "Successfully installed xerion-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fLuvTGrfF0SZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4de2d8a4-2453-442b-d82e-54516f7bd1dc"
      },
      "cell_type": "code",
      "source": [
        "# インストール結果を確認します\n",
        "import numpy as np\n",
        "from xerion.xerion import Xerion\n",
        "\n",
        "data = Xerion()\n",
        "##descr() はデータの諸元を表示します\n",
        "#data.descr()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.datadir=/content/xerion/xerion/data/\n",
            "self.datafilename=/content/xerion/xerion/data/SM-nsyl.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7jxitKkW9_iX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 手順2. データの読み込み"
      ]
    },
    {
      "metadata": {
        "id": "WOA81ch99_iY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c8d20dbf-3d05-480d-a708-322d3b85a61a"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from xerion.xerion import Xerion\n",
        "handson = Xerion()\n",
        "\n",
        "# Xerion は data 管理用モジュールです。以下のコメントを外してご覧ください\n",
        "#handson.descr()\n",
        "#handson.usage()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.datadir=/content/xerion/xerion/data/\n",
            "self.datafilename=/content/xerion/xerion/data/SM-nsyl.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aFlE7HnI9_ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c8454d6-bcd6-4dee-a7ee-b814bce77fdc"
      },
      "cell_type": "code",
      "source": [
        "grapheme = handson.db['grapheme']\n",
        "phoneme = handson.db['phoneme']\n",
        "seq = handson.db['seq']\n",
        "len(handson.db['grapheme'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "fOq3LKxg9_ig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 手順3. 読み込んだデータの確認\n",
        "\n",
        "ここに `input`, `output`, `freq`, `grapheme`, `phoneme`, `seq`, `tag` でアクセスできるようにしてあります。\n",
        "\n",
        "- input: np.ndarrray((2998, 105), dtype=float32) # 文字単語のトリプレット表現 105 次元ベクトル\n",
        "- output: np.ndarray((2998, 61), dtype=float32)  # 対応する音韻トリプレット表現 61 次元ベクトル\n",
        "- frep: np.ndarray((2998,), dtype=float32)       # 対応する頻度情報\n",
        "- seq: \n",
        "- grapheme: 入力文字列リスト\n",
        "- phoneme: 出力音韻列リスト ARPABET 表現\n",
        "- tag: 無視してください\n",
        "\n",
        "SM89, PMSP96 では意味層は実装されていません。<br>\n",
        "以下に例を示します"
      ]
    },
    {
      "metadata": {
        "id": "kyxWZNih9_ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "7b33f52c-3179-46c5-8e76-fee21049e2d7"
      },
      "cell_type": "code",
      "source": [
        "print(handson.tags)\n",
        "handson.grapheme, handson.phoneme, handson.freq, handson.seq, handson.inputs, handson.outputs, set(handson.tag)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('#', 'seq', 'grapheme', 'phoneme', 'freq', 'tag', 'inputs', 'outputs')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['ace', 'ache', 'act', ..., 'zone', 'zoo', 'zounds'], dtype='<U8'),\n",
              " array(['As', 'Ak', '@kt', ..., 'zOn', 'zU', 'zWnz'], dtype='<U6'),\n",
              " array([0.236101, 0.149313, 0.471041, ..., 0.213746, 0.199825, 0.115525],\n",
              "       dtype=float32),\n",
              " array([   0,    1,    2, ..., 2995, 2996, 2997], dtype=int16),\n",
              " array([[0, 0, 0, ..., 1, 0, 0],\n",
              "        [0, 0, 0, ..., 1, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 1, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16),\n",
              " {'#',\n",
              "  'AMB',\n",
              "  'CON',\n",
              "  'EXC',\n",
              "  'EXPT',\n",
              "  'HEC',\n",
              "  'HFE',\n",
              "  'HFEEXPT',\n",
              "  'HFRIC',\n",
              "  'HRI',\n",
              "  'HSTR',\n",
              "  'HSTRUNQ',\n",
              "  'LEC',\n",
              "  'LFE',\n",
              "  'LFEEXPT',\n",
              "  'LFRI',\n",
              "  'LRIC',\n",
              "  'LRICCON',\n",
              "  'LSTR',\n",
              "  'LSTRUNQ',\n",
              "  'REG',\n",
              "  'RI',\n",
              "  'STR',\n",
              "  'STREXPT',\n",
              "  'UNQ',\n",
              "  'homg'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "krvJIeIm9_il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##最初，このセルは無視してください\n",
        "#print(handson.url_base, handson.url_file)\n",
        "#print(handson.basefilename)\n",
        "#print(handson.syl_files, '\\n', handson.nsyl_files)\n",
        "#print(handson.datadir)\n",
        "#print(handson.datafilenames)\n",
        "#print(type(handson.db), len(handson.db))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7ghtszo9_io",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1baf6d33-3038-4e32-efc7-d9a0159db643"
      },
      "cell_type": "code",
      "source": [
        "type(handson.db)\n",
        "for k in handson.db.keys():\n",
        "    print(k, end=' ')\n",
        "    if isinstance(handson.db[k], list):\n",
        "        print(len(handson.db[k]))\n",
        "    elif isinstance(handson.db[k], np.ndarray):\n",
        "        print(handson.db[k].shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs (2998, 105)\n",
            "outputs (2998, 61)\n",
            "grapheme (2998,)\n",
            "phoneme (2998,)\n",
            "freq (2998,)\n",
            "tag 2998\n",
            "seq (2998,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kvVdxKuV9_iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "5dbe260d-7f8f-453e-9089-e36a8ccf5c82"
      },
      "cell_type": "code",
      "source": [
        "## 各データを表示します\n",
        "handson.freq        ### データ内の各単語の頻度\n",
        "handson.grapheme    ### 各単語の表記表現\n",
        "handson.phoneme     ### 各単語の音韻表現\n",
        "len(handson.inputs), handson.inputs.shape, handson.inputs     ###入力表現 numpy の ndarray\n",
        "len(handson.outputs), handson.outputs.shape, handson.outputs  ###出力表現 numpy の ndarray"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2998, (2998, 61), array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "pF7mND3F9_ix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e9826098-3a05-4edc-fba5-d3eb310b1b65"
      },
      "cell_type": "code",
      "source": [
        "#以下に 3 連表現を示します。PMSP96論文中では triplet と呼ばれていたオンセット onset，母音 vowel, コーダ coda です。\n",
        "for item in [handson.Orthography, handson.Phonology]:\n",
        "    for entry in ['onset', 'vowel', 'coda']:\n",
        "        print(item[entry])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Y', 'S', 'P', 'T', 'K', 'Q', 'C', 'B', 'D', 'G', 'F', 'V', 'J', 'Z', 'L', 'M', 'N', 'R', 'W', 'H', 'CH', 'GH', 'GN', 'PH', 'PS', 'RH', 'SH', 'TH', 'TS', 'WH']\n",
            "['E', 'I', 'O', 'U', 'A', 'Y', 'AI', 'AU', 'AW', 'AY', 'EA', 'EE', 'EI', 'EU', 'EW', 'EY', 'IE', 'OA', 'OE', 'OI', 'OO', 'OU', 'OW', 'OY', 'UE', 'UI', 'UY']\n",
            "['H', 'R', 'L', 'M', 'N', 'B', 'D', 'G', 'C', 'X', 'F', 'V', '∫', 'S', 'Z', 'P', 'T', 'K', 'Q', 'BB', 'CH', 'CK', 'DD', 'DG', 'FF', 'GG', 'GH', 'GN', 'KS', 'LL', 'NG', 'NN', 'PH', 'PP', 'PS', 'RR', 'SH', 'SL', 'SS', 'TCH', 'TH', 'TS', 'TT', 'ZZ', 'U', 'E', 'ES', 'ED']\n",
            "['s', 'S', 'C', 'z', 'Z', 'j', 'f', 'v', 'T', 'D', 'p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'h', 'I', 'r', 'w', 'y']\n",
            "['a', 'e', 'i', 'o', 'u', '@', '^', 'A', 'E', 'I', 'O', 'U', 'W', 'Y']\n",
            "['r', 'I', 'm', 'n', 'N', 'b', 'g', 'd', 'ps', 'ks', 'ts', 's', 'z', 'f', 'v', 'p', 'k', 't', 'S', 'Z', 'T', 'D', 'C', 'j']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9glST6r9_i0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 同形異音語について"
      ]
    },
    {
      "metadata": {
        "id": "7a4QG-c99_i1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eea4c5d9-128e-409e-e02d-66e0c78e0bba"
      },
      "cell_type": "code",
      "source": [
        "len(handson.grapheme), type(handson.grapheme)\n",
        "grapheme_set = set(handson.grapheme)\n",
        "len(grapheme_set)\n",
        "\n",
        "print('データ総数:{0} とユニークなデータ数:{1} との差が同形異音語数になります'.format(\n",
        "    len(handson.grapheme),len(grapheme_set)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "データ総数:2998 とユニークなデータ数:2985 との差が同形異音語数になります\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l3Qgx_fz9_i4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2342480f-c865-4ed1-f192-bc1dd23d2f28"
      },
      "cell_type": "code",
      "source": [
        "# 実際に同形異音語を表示してみましょう\n",
        "prev_word = \"\"\n",
        "n_homographs = 0\n",
        "for word in sorted(handson.grapheme):\n",
        "    if word == prev_word:\n",
        "        n_homographs += 1\n",
        "        print(word, end=' ')\n",
        "    prev_word = word\n",
        "print('\\nn_homographs={}'.format(n_homographs)) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bass bow dove house lead live read route row sow tear wind wound \n",
            "n_homographs=13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WqYB3h2n9_i6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### 以下は知らなくても良い情報ですので無視してください for debuging\n",
        "#handson.load_pickle()\n",
        "#data.make_all()\n",
        "#print(handson.module_path)\n",
        "#handson.note()\n",
        "#handson.nsyl_files\n",
        "#handson.origfile_size\n",
        "#print(handson.Orthography)\n",
        "#print(handson.Phonology)\n",
        "#print(handson.pkl_dir)\n",
        "#handson.url_base\n",
        "#handson.url_file\n",
        "#handson.xerion_prefix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEThCJSF9_i9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e506d246-f635-4513-f756-482db029abbb"
      },
      "cell_type": "code",
      "source": [
        "for db in handson.dbs:\n",
        "    print('database: ', db) # , db.dbs[db][3].shape, type(db.dbs[db][3])) #, x.dbs[db][3])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "database:  SM-nsyl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JxGjLhNa9_jA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# データないに登録された各単語の発音を調べる\n",
        "\n",
        "- pyhon で自然言語処理する際に使われる `nltk` を使って単語の発音を調べてみます。\n",
        "- `nltk` については [https://www.nltk.org/](https://www.nltk.org/) をご覧ください"
      ]
    },
    {
      "metadata": {
        "id": "4xr1IdLx9_jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "897283d1-3750-487e-ce6e-023b6bed2870"
      },
      "cell_type": "code",
      "source": [
        "# Colaboratory では cmudict がダウンロードされいないようなのでダウンロードします\n",
        "# 一度だけ実行すればよいので，その都度実行する必要はありません\n",
        "import nltk\n",
        "nltk.download('cmudict')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Ugdv9Mh09_jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8f9fd321-2260-4676-cf59-56411b5c9e38"
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import cmudict\n",
        "arpabet = cmudict.dict()\n",
        "\n",
        "# 1. Xerion の単語を取り出します\n",
        "words = handson.db['grapheme']\n",
        "\n",
        "# 2. Xerion に存在する単語のうち cmudict に発音の登録のない単語を抜き出します。\n",
        "not_in_arpabet = [word for word in words if not word in arpabet]\n",
        "\n",
        "print('{0}/{1}={2:.2f} percent words in Xerion data were not registered in ARPABET.'\n",
        "      .format(len(not_in_arpabet), len(words), len(not_in_arpabet)/len(words)*100))\n",
        "\n",
        "# 随分ありますね。\n",
        "print(not_in_arpabet)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/2998=1.83 percent words in Xerion data were not registered in ARPABET.\n",
            "['awn', 'bas', 'bilge', 'bleat', 'calve', 'cheep', 'chive', 'clod', 'clop', 'clove', 'crag', 'cud', 'dork', 'fiche', 'flays', 'frappe', 'git', 'gunk', 'hasp', 'jag', 'jape', 'laze', 'leer', 'letch', 'manse', 'muss', 'nape', 'paunch', 'phage', 'pram', 'rend', 'retch', 'rheum', 'rime', 'runt', 'scrim', 'shoal', 'shush', 'snoot', 'sooth', 'souse', 'sprig', 'squaw', 'thwack', 'tog', 'tyme', 'ump', 'veldt', 'vend', 'whelp', 'whil', 'whir', 'wretch', 'yawl', 'zit']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yLdAaV8V9_jI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "426fbffa-d001-4532-d04d-f0a8e9864275"
      },
      "cell_type": "code",
      "source": [
        "# ちなみに cmu 辞書についてですが\n",
        "print(len(arpabet))\n",
        "\n",
        "arpabet_vocab = [v for v in arpabet.keys()]\n",
        "print(arpabet_vocab[:5])\n",
        "arpabet_sounds = [s for s in arpabet.values()]\n",
        "print(arpabet_sounds[:5])\n",
        "#上記の表記については ARPABET をご覧ください"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123455\n",
            "['a', 'a.', 'a42128', 'aaa', 'aaberg']\n",
            "[[['AH0'], ['EY1']], [['EY1']], [['EY1', 'F', 'AO1', 'R', 'T', 'UW1', 'W', 'AH1', 'N', 'T', 'UW1', 'EY1', 'T']], [['T', 'R', 'IH2', 'P', 'AH0', 'L', 'EY1']], [['AA1', 'B', 'ER0', 'G']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8aVOWZvK9_jL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ARPABET に登録されていない単語の処理"
      ]
    },
    {
      "metadata": {
        "id": "LaWJstQK9_jN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "outputId": "3ce7a897-55b7-4c28-b877-27a6d1b4525b"
      },
      "cell_type": "code",
      "source": [
        "from itertools import product as iterprod\n",
        "#arpabet = nltk.corpus.cmudict.dict()\n",
        "\n",
        "def wordbreak(s):\n",
        "    \"\"\"\n",
        "    See https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
        "\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    if s in arpabet:\n",
        "        return arpabet[s]\n",
        "    middle = len(s)/2\n",
        "    partition = sorted(list(range(len(s))), key=lambda x: (x-middle)**2-x)\n",
        "    for i in partition:\n",
        "        pre, suf = (s[:i], s[i:])\n",
        "        if pre in arpabet and wordbreak(suf) is not None:\n",
        "            return [x+y for x,y in iterprod(arpabet[pre], wordbreak(suf))]\n",
        "    return None\n",
        "\n",
        "# nltk の cmudict に存在しない単語の読みを表示\n",
        "for word in not_in_arpabet:\n",
        "    print(word, wordbreak(word))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "awn [['AO1', 'EH1', 'N']]\n",
            "bas [['B', 'IY1', 'AE1', 'Z'], ['B', 'IY1', 'EH1', 'Z']]\n",
            "bilge [['B', 'IH1', 'L', 'JH', 'IY1', 'IY1']]\n",
            "bleat [['B', 'L', 'IY1', 'T', 'IY1']]\n",
            "calve [['K', 'AE1', 'L', 'V', 'IY1'], ['K', 'AE1', 'L', 'V', 'IY1', 'IY1']]\n",
            "cheep [['CH', 'EY1', 'IY1', 'P', 'IY1']]\n",
            "chive [['K', 'AY1', 'V', 'IY1'], ['K', 'AY1', 'V', 'IY1', 'IY1']]\n",
            "clod [['S', 'IY1', 'L', 'OW1', 'D', 'IY1']]\n",
            "clop [['S', 'IY1', 'L', 'AA1', 'P']]\n",
            "clove [['S', 'IY1', 'L', 'AH1', 'V']]\n",
            "crag [['S', 'IY1', 'R', 'AE1', 'G']]\n",
            "cud [['S', 'IY1', 'Y', 'UW1', 'D', 'IY1']]\n",
            "dork [['D', 'UW1', 'AA1', 'R', 'K', 'EY1']]\n",
            "fiche [['F', 'AY1', 'CH', 'EY1'], ['F', 'IY1', 'CH', 'EY1']]\n",
            "flays [['F', 'L', 'EY1', 'EH1', 'S']]\n",
            "frappe [['F', 'R', 'AE1', 'P', 'P', 'IY1', 'IY1']]\n",
            "git [['JH', 'IY1', 'IH1', 'T'], ['JH', 'IY1', 'IH0', 'T']]\n",
            "gunk [['G', 'UW1', 'EH1', 'N', 'K', 'EY1']]\n",
            "hasp [['HH', 'AA1', 'EH1', 'S', 'P', 'IY1'], ['EY1', 'CH', 'EY1', 'EH1', 'S', 'P', 'IY1']]\n",
            "jag [['Y', 'AA1', 'JH', 'IY1']]\n",
            "jape [['Y', 'AA1', 'P', 'IY1', 'IY1']]\n",
            "laze [['L', 'AA1', 'Z', 'IY1']]\n",
            "leer [['L', 'AH0', 'ER0']]\n",
            "letch [['L', 'EH1', 'T', 'S', 'IY1', 'EY1', 'CH']]\n",
            "manse [['M', 'AE1', 'N', 'S', 'AW2', 'TH', 'IY1', 'S', 'T'], ['M', 'AE1', 'N', 'S', 'EY1'], ['M', 'AE1', 'N', 'EH1', 'S', 'IY1']]\n",
            "muss [['M', 'UW1', 'EH1', 'S', 'EH1', 'S']]\n",
            "nape [['N', 'AA1', 'P', 'IY1', 'IY1']]\n",
            "paunch [['P', 'AA1', 'AH1', 'N', 'S', 'IY1', 'EY1', 'CH'], ['P', 'AA1', 'Y', 'UW1', 'EH1', 'N', 'S', 'IY1', 'EY1', 'CH']]\n",
            "phage [['P', 'IY1', 'EY1', 'CH', 'EY1', 'JH']]\n",
            "pram [['P', 'IY1', 'R', 'AE1', 'M']]\n",
            "rend [['R', 'EY1', 'EH1', 'N', 'D', 'IY1'], ['R', 'IY1', 'EH1', 'N', 'D', 'IY1']]\n",
            "retch [['R', 'EH1', 'T', 'S', 'IY1', 'EY1', 'CH']]\n",
            "rheum [['AA1', 'R', 'HH', 'IY1', 'AH1', 'M']]\n",
            "rime [['R', 'IH1', 'M', 'IY1']]\n",
            "runt [['R', 'UW1', 'EH1', 'N', 'T', 'IY1'], ['AA1', 'R', 'Y', 'UW1', 'EH1', 'N', 'T', 'IY1']]\n",
            "scrim [['EH1', 'S', 'K', 'R', 'IH1', 'M']]\n",
            "shoal [['EH1', 'S', 'EY1', 'CH', 'OW1', 'AE1', 'L']]\n",
            "shush [['SH', 'UW1', 'EH1', 'S', 'EY1', 'CH']]\n",
            "snoot [['EH1', 'S', 'N', 'OW1', 'AO1', 'T'], ['EH1', 'S', 'N', 'OW1', 'OW1', 'T', 'IY1']]\n",
            "sooth [['S', 'UW1', 'T', 'IY1', 'EY1', 'CH']]\n",
            "souse [['S', 'OW1', 'Y', 'UW1', 'S'], ['S', 'OW1', 'Y', 'UW1', 'Z']]\n",
            "sprig [['EH1', 'S', 'P', 'R', 'IH1', 'G']]\n",
            "squaw [['EH1', 'S', 'K', 'UW1', 'AO1']]\n",
            "thwack [['T', 'IY1', 'EY1', 'CH', 'W', 'AE1', 'K']]\n",
            "tog [['T', 'UW1', 'JH', 'IY1'], ['T', 'IH0', 'JH', 'IY1'], ['T', 'AH0', 'JH', 'IY1']]\n",
            "tyme [['T', 'AY1', 'M', 'IY1']]\n",
            "ump [['AH1', 'M', 'P', 'IY1']]\n",
            "veldt [['V', 'IY1', 'EH1', 'L', 'D', 'IY1', 'T', 'IY1'], ['V', 'IY1', 'IY1', 'EH1', 'L', 'D', 'IY1', 'T', 'IY1']]\n",
            "vend [['V', 'IY1', 'EH1', 'N', 'D', 'IY1'], ['V', 'IY1', 'IY1', 'EH1', 'N', 'D', 'IY1']]\n",
            "whelp [['D', 'AH1', 'B', 'AH0', 'L', 'Y', 'UW0', 'HH', 'EH1', 'L', 'P']]\n",
            "whil [['D', 'AH1', 'B', 'AH0', 'L', 'Y', 'UW0', 'HH', 'AY1', 'EH1', 'L']]\n",
            "whir [['D', 'AH1', 'B', 'AH0', 'L', 'Y', 'UW0', 'HH', 'AY1', 'AA1', 'R']]\n",
            "wretch [['D', 'AH1', 'B', 'AH0', 'L', 'Y', 'UW0', 'R', 'EH1', 'T', 'S', 'IY1', 'EY1', 'CH']]\n",
            "yawl [['Y', 'AA1', 'D', 'AH1', 'B', 'AH0', 'L', 'Y', 'UW0', 'EH1', 'L']]\n",
            "zit [['Z', 'IY1', 'T', 'IY1']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_92WfwDD9_jQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 意味層の実装\n",
        "\n",
        "from <https://fasttext.cc/docs/en/pretrained-vectors.html>"
      ]
    },
    {
      "metadata": {
        "id": "HBy5GPFt9_jQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "a062dac7-4f99-4f31-e828-1bd65272811d"
      },
      "cell_type": "code",
      "source": [
        "# fastText データの読み込み。次の行頭の # を外してください\n",
        "#!time wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-18 00:13:06--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6597238061 (6.1G) [binary/octet-stream]\n",
            "Saving to: ‘wiki.en.vec’\n",
            "\n",
            "wiki.en.vec          70%[=============>      ]   4.34G  38.4MB/s    eta 78s    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IWQUyxPA9_jS",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d1a3e5d-49aa-4d0a-e810-eee28c78d488"
      },
      "cell_type": "code",
      "source": [
        "word2vec_file = 'wiki.en.vec'\n",
        "with open(word2vec_file, 'r') as f:\n",
        "    lines = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 2998)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "YBt7olyq9_jV",
        "colab_type": "code",
        "colab": {},
        "outputId": "f580b09b-209c-452d-f7f8-431791f38f41"
      },
      "cell_type": "code",
      "source": [
        "words_list = list(handson.grapheme)\n",
        "type(words_list), len(words_list)\n",
        "semantics_wiki = {}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 2998)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "Q23_ttQB9_jX",
        "colab_type": "code",
        "colab": {},
        "outputId": "64510a58-414d-4606-f7de-0e5eed03871e"
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "for line in lines:    \n",
        "    buff = line.strip().split(' ')\n",
        "    word = buff[0]\n",
        "    if word in words_list:\n",
        "        semantics_wiki[word] = np.asarray([float(x) for x in buff[1:]],dtype=np.float32)\n",
        "\n",
        "#同形異音語があるので，その数だけ semantics は数が少ないです。\n",
        "len(semantics_wiki), type(semantics_wiki)\n",
        "semantics = np.ndarray((len(words_list), 300), dtype=np.float32)\n",
        "# そこで数合わせをします"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2min 15s ± 809 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZbB3isG9_jZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "semantics = np.ndarray((len(words_list), 300), dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHLABVTZ9_jc",
        "colab_type": "code",
        "colab": {},
        "outputId": "14dfb7f6-a110-48d0-c9cc-150e37c69779"
      },
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "for i, w in enumerate(words_list):\n",
        "    semantics[i] = semantics_wiki[w]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.48 ms ± 118 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "czje78VK9_je",
        "colab_type": "code",
        "colab": {},
        "outputId": "a9787aa9-fc5d-42ce-89b1-fab3e7fb3f20"
      },
      "cell_type": "code",
      "source": [
        "handson.sememe = semantics\n",
        "for modality in [handson.grapheme, handson.phoneme, handson.sememe]:\n",
        "    len(modality), type(modality), modality.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2998, numpy.ndarray, (2998,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2998, numpy.ndarray, (2998,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2998, numpy.ndarray, (2998, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "metadata": {
        "id": "OfxJ_rek9_jh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 視覚化"
      ]
    },
    {
      "metadata": {
        "id": "OyWzFToI9_ji",
        "colab_type": "code",
        "colab": {},
        "outputId": "ad23f8d2-5617-49de-86ae-84d271dbda26"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "G = handson.db['inputs']\n",
        "pca = PCA(n_components=4)\n",
        "pca.fit(G)\n",
        "print(pca.explained_variance_ratio_) \n",
        "\n",
        "S = handson.sememe\n",
        "pca.fit(S)\n",
        "print(pca.explained_variance_ratio_) \n",
        "\n",
        "P = handson.db['outputs']\n",
        "pca.fit(P)\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
              "  svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        },
        {
          "output_type": "stream",
          "text": [
            "[0.07402131 0.058128   0.05556856 0.04860908]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
              "  svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        },
        {
          "output_type": "stream",
          "text": [
            "[0.02843864 0.02434086 0.02053765 0.01836787]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
              "  svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        },
        {
          "output_type": "stream",
          "text": [
            "[0.05501097 0.04969663 0.0479385  0.0450488 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F22TaXxS9_jk",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a87056d-96b7-40e2-bf1d-d26ebf02ea28"
      },
      "cell_type": "code",
      "source": [
        "pca.get_params()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'copy': True,\n",
              " 'iterated_power': 'auto',\n",
              " 'n_components': 2,\n",
              " 'random_state': None,\n",
              " 'svd_solver': 'auto',\n",
              " 'tol': 0.0,\n",
              " 'whiten': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "U-59g-mH9_jo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "handson.input.shape\n",
        "len(semantics)\n",
        "handson.grapheme[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ta-hRG7B9_jq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for word in handson.grapheme[:3]:\n",
        "    print(word, semantics[word].shape, semantics[word].dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUxqYQ4G9_jr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#type(semantics)\n",
        "type(handson.grapheme), handson.grapheme.shape, handson.grapheme[:3]\n",
        "type(handson.phoneme), handson.phoneme.shape, handson.phoneme[:3]\n",
        "type(handson.sememe), handson.sememe.shape, handson.sememe[:3]\n",
        "type(handson.freq), handson.freq.shape, handson.freq[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmx3lOaI9_js",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 同形異音文字の表示\n",
        "<!--\n",
        "- [](https://en.wikipedia.org/wiki/File:Homograph_homophone_venn_diagram.svg)\n",
        "- [](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Homograph_homophone_venn_diagram.svg/1280px-Homograph_homophone_venn_diagram.svg.png)\n",
        "-->\n",
        "\n",
        "<div>\n",
        "<center>\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Homograph_homophone_venn_diagram.svg/1280px-Homograph_homophone_venn_diagram.svg.png\" style=\"width:29%\"><br>\n",
        "from [https://en.wikipedia.org/wiki/Heteronym_(linguistics)](https://en.wikipedia.org/wiki/Heteronym_(linguistics))<br>\n",
        "\n",
        "from <https://en.wikipedia.org/wiki/Heteronym_(linguistics)>\n",
        "</center>\n",
        "\n",
        "see also <http://www.singularis.ltd.uk/bifroest/misc/homophones-list.html>\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "JBv3PzGy9_jt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = handson.graph # orthography\n",
        "prev_word = None\n",
        "same_count = 0\n",
        "for i, word in enumerate(words):\n",
        "    if not word in semantics:\n",
        "        print(i, word)  #, wrd2idx[word], semantics[word])\n",
        "        del orthography[word]\n",
        "        del phonology[word]\n",
        "    if prev_word == word:\n",
        "        same_count += 1\n",
        "        print(word, end=' ')\n",
        "    prev_word = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbC1WIZe9_jv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}